import pandas as pd
import os
from datetime import datetime
import re

# --- 1. CONFIGURATION ---
# On se place dynamiquement
current_dir = os.path.dirname(os.path.abspath(__file__))
# Si le script est dans un sous-dossier, on remonte. Sinon on reste lÃ .
if "scrapers" in current_dir:
    project_root = os.path.dirname(os.path.dirname(current_dir)) # Remonte 2 fois (scrapers/nom_dossier)
    if "PathFinder" not in project_root: # SÃ©curitÃ© si structure diffÃ©rente
         project_root = os.path.dirname(current_dir)
else:
    project_root = current_dir

# Chemins des fichiers PROPRES
FILE_FT = os.path.join(project_root, "data", "clean", "offres_francetravail_clean.csv")
FILE_WTTJ = os.path.join(project_root, "data", "clean", "offres_wttj_clean.csv")
FILE_APEC = os.path.join(project_root, "data", "clean", "offres_apec_clean.csv")

OUTPUT_CSV = os.path.join(project_root, "data", "clean", "global_job_market.csv")

# CrÃ©ation du dossier final s'il n'existe pas
os.makedirs(os.path.dirname(OUTPUT_CSV), exist_ok=True)

print("ðŸ§ª DÃ©marrage de la fusion...")

# --- FONCTION DE CLASSIFICATION (NIVEAU) ---
def determiner_niveau(row):
    """
    DÃ©duit le niveau d'expÃ©rience (Etudiant, Junior, ConfirmÃ©, Senior) 
    basÃ© sur le salaire (distingue idf des autres zones) et les mots-clÃ©s du titre.
    """
    titre = str(row['Titre']).lower() if pd.notna(row['Titre']) else ""
    desc = str(row['Description']).lower() if pd.notna(row['Description']) else "" 
    lieu = str(row['Ville']).lower() if pd.notna(row['Ville']) else "" 
    salaire = row['Salaire_Annuel']
    contrat = str(row['Type_Contrat']).lower() if pd.notna(row['Type_Contrat']) else ""

    # --- 2. DÃ‰TECTION STAGE (PrioritÃ© absolue) ---
    mots_stage = ["stage", "internship", "alternance", "alternant", "stagiaire", "apprentissage", "contrat pro"]
    if any(k in contrat for k in mots_stage) or any(k in titre for k in mots_stage) or any(k in desc for k in mots_stage):
        return "Stage / Alternance"

    # --- 3. DÃ‰FINITION DES SEUILS SELON LA GÃ‰OGRAPHIE ---
    # Liste des mots qui indiquent la rÃ©gion parisienne
    # Zone A : Paris & IDF
    mots_idf = ['paris', 'Ã®le-de-france', 'ile-de-france', 'boulogne', 'courbevoie', 'la dÃ©fense', '92', '75', '93', '94']
    
    # Zone B : Grandes MÃ©tropoles (MarchÃ© dynamique)
    mots_metropoles = ['lyon', 'toulouse', 'bordeaux', 'nantes', 'lille', 'aix', 'marseille', 'nice', 'rennes', 'sophia', 'antipolis']

    if any(m in lieu for m in mots_idf):
        # ZONE PARIS
        seuil_junior = 40000
        seuil_senior = 60000
    elif any(m in lieu for m in mots_metropoles):
        # ZONE GRANDES VILLES (IntermÃ©diaire)
        seuil_junior = 37000  # Un junior Ã  Lyon peut toucher 36-37k
        seuil_senior = 52000  # 52k Ã  Bordeaux, c'est clairement un profil Senior
    else:
        # ZONE RESTE DE LA FRANCE
        seuil_junior = 34000
        seuil_senior = 48000

    # --- 4. LE VERDICT DU SALAIRE ---
    if pd.notna(salaire) and salaire > 0:
        if salaire <= seuil_junior:
            return "Junior"
        elif seuil_junior < salaire < seuil_senior:
            return "ConfirmÃ©"
        else:
            return "Senior"

    # --- 5. FALLBACK : ANALYSE TEXTUELLE ---
    # (Titre)
    if any(k in titre for k in ["senior", "lead", "manager", "head of", "directeur", "expert", "principal", "vp"]):
        return "Senior"
    if any(k in titre for k in ["junior", "dÃ©butant", "assistant", "graduate"]):
        return "Junior"
    if "confirmÃ©" in titre:
        return "ConfirmÃ©"

    # (Description - AnnÃ©es)
    pattern = r"(\d{1,2})\s*?(?:-|\s)?\s*?(?:ans|annÃ©es|years|year)"
    match = re.search(pattern, desc)
    if match:
        annees = int(match.group(1))
        if annees < 3: return "Junior"
        elif 3 <= annees <= 5: return "ConfirmÃ©"
        else: return "Senior"

    return "Non spÃ©cifiÃ©"

# --- 2. CHARGEMENT ET STANDARDISATION ---
dataframes = []

# --- A. FRANCE TRAVAIL ---
if os.path.exists(FILE_FT):
    print("ðŸ”¹ Chargement France Travail...")
    df_ft = pd.read_csv(FILE_FT)
    # Renommage pour standardiser
    df_ft = df_ft.rename(columns={
        "Ville_Clean": "Ville",
        "Salaire_Annuel_Estime": "Salaire_Annuel",
        "Description_Propre": "Description",
        "Date_Publication": "Date"
    })
    # Ajout colonnes manquantes
    df_ft["Teletravail"] = "Non spÃ©cifiÃ©" 
    # SÃ©lection stricte des colonnes
    cols = ["Titre", "Entreprise", "Ville", "Salaire_Annuel", "Type_Contrat", "Teletravail", "Date", "Source", "URL", "Description"]
    # On gÃ¨re si certaines colonnes manquent dans le CSV source
    for c in cols:
        if c not in df_ft.columns: df_ft[c] = None
    dataframes.append(df_ft[cols])
else:
    print("âš ï¸ Fichier France Travail introuvable !")

# --- B. WTTJ ---
if os.path.exists(FILE_WTTJ):
    print("ðŸ”¹ Chargement WTTJ...")
    df_wttj = pd.read_csv(FILE_WTTJ)
    
    df_wttj = df_wttj.rename(columns={
        "Ville_Clean": "Ville",
        "Salaire_Annuel_Estime": "Salaire_Annuel",
        "Description_Propre": "Description"
    })
    
    # Ajout Source et Date (Aujourd'hui)
    df_wttj["Source"] = "Welcome to the Jungle"
    df_wttj["Date"] = datetime.today().strftime('%Y-%m-%d')
    
    cols = ["Titre", "Entreprise", "Ville", "Salaire_Annuel", "Type_Contrat", "Teletravail", "Date", "Source", "URL", "Description"]
    for c in cols:
        if c not in df_wttj.columns: df_wttj[c] = None
    dataframes.append(df_wttj[cols])
else:
    print("âš ï¸ Fichier WTTJ introuvable !")

# --- C. APEC ---
if os.path.exists(FILE_APEC):
    print("ðŸ”¹ Chargement APEC...")
    df_apec = pd.read_csv(FILE_APEC)
    
    df_apec = df_apec.rename(columns={
        "Ville_Clean": "Ville",
        "Salaire_Annuel_Estime": "Salaire_Annuel",
        "Description_Propre": "Description"
    })
    
    df_apec["Source"] = "Apec"
    df_apec["Date"] = datetime.today().strftime('%Y-%m-%d')
    df_apec["Teletravail"] = "Non spÃ©cifiÃ©"
    
    cols = ["Titre", "Entreprise", "Ville", "Salaire_Annuel", "Type_Contrat", "Teletravail", "Date", "Source", "URL", "Description"]
    for c in cols:
        if c not in df_apec.columns: df_apec[c] = None
    dataframes.append(df_apec[cols])
else:
    print("âš ï¸ Fichier APEC introuvable !")

# --- 3. FUSION ---

if not dataframes:
    print("âŒ Aucun fichier chargÃ©. ArrÃªt.")
    exit()

print("ðŸŒªï¸  MÃ©lange des donnÃ©es...")
df_final = pd.concat(dataframes, ignore_index=True)

# === LE NETTOYAGE ===

print("âœ¨ Nettoyage et Harmonisation des Contrats...")

# 1. Nettoyage de base : String + Strip (enlÃ¨ve espaces) + Capitalize (Cdi, Stage, Cdd...)
# Cela regroupe automatiquement "cdi", "CDI" et "Cdi" sous la forme "Cdi"
df_final["Type_Contrat"] = df_final["Type_Contrat"].astype(str).str.strip().str.capitalize()

# 2. Dictionnaire de traduction et remise en forme (Cdi -> CDI)
# Note : Comme on a fait .capitalize() juste avant, "MIS" est devenu "Mis" et "LIB" est devenu "Lib"
corrections_contrat = {
    "Mis": "IntÃ©rim",
    "Lib": "Freelance",
    "Din": "CDI IntÃ©rimaire",
    "Cdi": "CDI",  # On remet en majuscules
    "Cdd": "CDD",  # On remet en majuscules
    "Nan": "Non spÃ©cifiÃ©" # GÃ¨re les valeurs vides
}

print("ðŸ§¹ Standardisation des grandes villes (Arrondissements)...")

df_final['Ville'] = df_final['Ville'].astype(str).str.replace(r'(?i)^paris.*', 'Paris', regex=True)
df_final['Ville'] = df_final['Ville'].str.replace(r'(?i)^lyon.*', 'Lyon', regex=True)
df_final['Ville'] = df_final['Ville'].str.replace(r'(?i)^marseille.*', 'Marseille', regex=True)

# Correction spÃ©cifique pour "La DÃ©fense" qui apparaÃ®t parfois comme "Puteaux" ou "Courbevoie"
# (Optionnel, mais utile pour regrouper les offres de ce hub)
# df_final['Ville'] = df_final['Ville'].replace(['Courbevoie', 'Puteaux', 'Nanterre'], 'La DÃ©fense')

# 3. Application des corrections
df_final["Type_Contrat"] = df_final["Type_Contrat"].replace(corrections_contrat)
print("âœ¨ Nettoyage des guillemets rÃ©siduels...")
cols_text = ['Titre', 'Entreprise', 'Ville']
for col in cols_text:
    # On force en string, on remplace les " et on enlÃ¨ve les espaces vides
    df_final[col] = df_final[col].astype(str).str.replace('"', '', regex=False).str.strip()
    
    # On enlÃ¨ve les "nan" qui apparaissent parfois lors de la conversion string
    df_final[col] = df_final[col].replace('nan', 'Non spÃ©cifiÃ©')

# Suppression des doublons (basÃ© sur l'URL)
len_avant = len(df_final)
df_final = df_final.drop_duplicates(subset=["URL"])
len_apres = len(df_final)

print(f"ðŸ§¹ Doublons supprimÃ©s : {len_avant - len_apres}")

# === CALCUL DU NIVEAU D'EXPÃ‰RIENCE ===
print("ðŸ§  Calcul des niveaux d'expÃ©rience (Analyse Salaires & Texte)...")
# On applique la fonction ligne par ligne (axis=1)
df_final['Niveau'] = df_final.apply(determiner_niveau, axis=1)

# --- 4. SAUVEGARDE ---
df_final.to_csv(OUTPUT_CSV, index=False)

print(f"\nâœ… TERMINÃ‰ ! Le fichier global est prÃªt :")
print(f"ðŸ‘‰ {OUTPUT_CSV}")
print("\nðŸ“Š STATISTIQUES FINALES :")
print(df_final["Source"].value_counts())
print(f"\nðŸ’° Offres avec salaire : {df_final['Salaire_Annuel'].notna().sum()}")