PathFinder : L'Analyseur du March√© de l'Emploi Data

![Python](https://img.shields.io/badge/Python-3.9%2B-blue)
![Streamlit](https://img.shields.io/badge/Frontend-Streamlit-red)
![Status](https://img.shields.io/badge/Status-Active-success)

**PathFinder** est une pipeline de donn√©es ETL (Extract, Transform, Load) et un dashboard interactif con√ßu pour **monitorer les tendances** du march√© de l'emploi Data en France.
Plut√¥t que de naviguer sur plusieurs sites diff√©rents, ce dashboard regroupe et nettoie les donn√©es de **trois plateformes cl√©s** (France Travail, APEC, Welcome to the Jungle) pour offrir une vision globale et centralis√©e des opportunit√©s accessibles.

 * `üîó (https://pathfinder-data.streamlit.app/)`

---

## Pourquoi ce projet ?

La recherche d'un premier emploi ou d'une alternance est souvent un parcours du combattant. J'ai cr√©√© cet outil pour r√©pondre √† des besoins concrets :
1.  **Centraliser :** Ne plus avoir √† ouvrir 10 onglets par jour pour surveiller les m√™mes mots-cl√©s.
2.  **D√©doublonner :** √âviter de lire trois fois la m√™me annonce publi√©e sur des sites diff√©rents.
3.  **Analyser :** Mieux comprendre quelles sont les comp√©tences (Tech Stack) r√©ellement demand√©es aux juniors aujourd'hui.

---

## Architecture & Pipeline

Le projet fonctionne de mani√®re autonome via une suite de scripts Python ex√©cut√©s de mani√®re **hebdomadaire** (avec une architecture pr√™te pour un passage en quotidien) :

### 1. Extraction (Scraping)
Des robots sp√©cialis√©s r√©cup√®rent les offres sur des sources institutionnelles et Tech :
* **France Travail** (via API/Web)
* **Welcome to the Jungle** (WTTJ)
* **APEC**

### 2. Transformation & Nettoyage
* **D√©duplication :** Identification des doublons via URL canoniques.
* **Harmonisation :** Standardisation des formats de dates et de lieux pour permettre le filtrage.
* **Gestion Temporelle (Persistance Historique):**
    * Si une offre est republi√©e, le syst√®me conserve la **date de publication originale** (la plus ancienne) pour calculer la vraie dur√©e de vie.
    * Le statut (Actif/Expir√©), lui, est mis √† jour √† la date la plus r√©cente.
* **Ciblage Junior :**
    * Analyse s√©mantique des descriptions et titres pour identifier sp√©cifiquement les opportunit√©s ouvertes aux d√©butants (0-3 ans d'exp√©rience).
    * Coh√©rence √©conomique (utilisation des seuils salariaux pour confirmer qu'un poste est ouvert √† un niveau d'entr√©e).


### 3. Visualisation (Streamlit)
Une application web interactive structur√©e en deux volets principaux :
* **Moteur de Recherche :** Filtrage dynamique des offres par mots-cl√©s (Stack technique), localisation et type de contrat.
* **Market Intelligence :** Tableaux de bord pour visualiser les tendances du march√©: **volume d'offres, typologie des contrats et stack technique.**

---

## Challenges Techniques & Solutions

### Le biais "Stock vs Flux"
Lors de l'initialisation de la base de donn√©es fin janvier 2026, j'ai observ√© un pic massif de 1800+ offres, suivi d'une chute √† ~160 offres/semaine.
* **Analyse :** Ce n'√©tait pas un effondrement du march√©, mais la distinction entre le **Stock** (historique accumul√©) et le **Flux** (nouvelles offres r√©elles).
* **Solution :** Impl√©mentation de marqueurs visuels dans les graphiques pour distinguer la phase d'initialisation de la phase de croisi√®re.

### Persistance des donn√©es
Mise en place d'un syst√®me de fusion (`pandas.concat` + `drop_duplicates`) robuste pour √©viter l'√©crasement de l'historique lors des mises √† jour r√©guli√®res.

---

## Stack Technique

* **Langage :** Python
* **Data Engineering :** Pandas, NumPy
* **Scraping :** Requests, BeautifulSoup
* **Visualisation :** Plotly Express, Streamlit
* **Versioning :** Git & GitHub

---

## Roadmap / Am√©liorations futures
[x] **Extraction :** Scraping fonctionnel de 3 sources.
[x] **Visualisation :** Dashboard Streamlit op√©rationnel.
[x] **D√©ploiement :** Mise en production de l'application (Streamlit Cloud) pour acc√®s public.
[ ] Passage du stockage CSV vers PostgreSQL (Supabase) pour fiabiliser les donn√©es et g√©rer la mont√©e en charge.
[ ] Parsing avanc√© des salaires (Regex) pour normaliser toutes les r√©mun√©rations en Brut Annuel.
[ ] Fr√©quence : Passage d'un scraping hebdomadaire √† un scraping quotidien (automatis√© via GitHub Actions).
[ ] Ajout de nouvelles sources.

üë§ **Auteur**
* **D√©velopp√© par Am-Tran** -[Mon LinkedIn](https://www.linkedin.com/in/am%C3%A9lie-tran-981325a5/)
